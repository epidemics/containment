{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../epimodel-covid-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.read_csv('COVID 19 Containment measures data.csv',parse_dates=['Date Start','Date end intended']).dropna(subset=['Country'])\n",
    "DATE = '2020_04_23'\n",
    "complete = pd.read_csv('Dataset completeness.csv')\n",
    "\n",
    "complete = complete[~pd.isna(complete['Complete up to date'])]['Country'].append(pd.Series(['United States']))\n",
    "\n",
    "masks = pd.read_csv('mask_survey_data.csv').drop(columns=['Unnamed: 0']).rename(columns={'country':'Country',\n",
    "                                                                                        'value':'Quantity',\n",
    "                                                                                        'date':'Date Start'})\n",
    "complete = complete.append(masks[masks['Country'].str.startswith('United States')]['Country'])\n",
    "cm = cm[cm['Country'].isin(complete)]\n",
    "masks = masks[masks['Country'].isin(complete)]\n",
    "ms = masks.groupby(['Country','Date Start']).mean().reset_index()\n",
    "ms['Keywords'] = 'public mask wearing data'\n",
    "ms['Source'] = 'Survey data'\n",
    "ms['Date Start'] = pd.to_datetime(ms['Date Start'])\n",
    "\n",
    "cm.loc[cm['Country'].str.startswith('United States')\n",
    "       &(~pd.isna(cm['Implementing State/Province'])),['Country']] = cm.loc[cm['Country'].str.startswith('United States')\n",
    "                                                                            &(~pd.isna(cm['Implementing State/Province'])),['Country']] +' - ' +cm.loc[cm['Country'].str.startswith('United States')\n",
    "                                                                                                            &(~pd.isna(cm['Implementing State/Province'])),['Implementing State/Province']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "acaps = pd.read_csv('/home/guest/Downloads/ef_acaps_combined.csv')\n",
    "\n",
    "# Bodgy mask features\n",
    "\n",
    "acaps.loc[1116,'Quantity'] = 5\n",
    "acaps.loc[1731,'Quantity'] = 40\n",
    "acaps.loc[(acaps['Keywords']=='public mask wearing data')&(pd.isna(acaps['Quantity'])),'Quantity']=80\n",
    "\n",
    "\n",
    "acaps['Date Start'] = pd.to_datetime(acaps['Date Start'])\n",
    "acaps = acaps.dropna(subset=['Date Start'])\n",
    "acaps_mask_data = acaps[(acaps['Keywords']=='public mask wearing data')&(acaps['DataSource']=='ACAPS')]\n",
    "acaps_mask_data = acaps_mask_data[acaps_mask_data['Country'].isin(complete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-03-16T00:00:00.000000000', '2020-02-01T00:00:00.000000000',\n",
       "       '2020-03-20T00:00:00.000000000', '2020-03-14T00:00:00.000000000',\n",
       "       '2020-02-26T00:00:00.000000000', '2020-03-18T00:00:00.000000000',\n",
       "       '2020-03-21T00:00:00.000000000', '2020-03-17T00:00:00.000000000',\n",
       "       '2020-03-13T00:00:00.000000000', '2020-03-11T00:00:00.000000000',\n",
       "       '2020-03-10T00:00:00.000000000', '2020-03-09T00:00:00.000000000',\n",
       "       '2020-03-05T00:00:00.000000000', '2020-03-04T00:00:00.000000000',\n",
       "       '2020-03-02T00:00:00.000000000', '2020-03-01T00:00:00.000000000',\n",
       "       '2020-02-29T00:00:00.000000000', '2020-02-27T00:00:00.000000000',\n",
       "       '2020-02-25T00:00:00.000000000', '2020-02-24T00:00:00.000000000',\n",
       "       '2020-02-23T00:00:00.000000000', '2020-02-22T00:00:00.000000000',\n",
       "       '2020-02-21T00:00:00.000000000', '2020-02-19T00:00:00.000000000',\n",
       "       '2020-02-18T00:00:00.000000000', '2020-02-07T00:00:00.000000000',\n",
       "       '2020-02-04T00:00:00.000000000', '2020-01-31T00:00:00.000000000',\n",
       "       '2020-01-30T00:00:00.000000000', '2020-01-08T00:00:00.000000000',\n",
       "       '2020-03-12T00:00:00.000000000', '2020-03-23T00:00:00.000000000',\n",
       "       '2020-03-24T00:00:00.000000000', '2020-03-19T00:00:00.000000000',\n",
       "       '2020-03-08T00:00:00.000000000', '2020-03-15T00:00:00.000000000',\n",
       "       '2020-02-17T00:00:00.000000000', '2020-03-29T00:00:00.000000000',\n",
       "       '2020-03-28T00:00:00.000000000', '2020-03-30T00:00:00.000000000',\n",
       "       '2020-03-27T00:00:00.000000000', '2020-03-25T00:00:00.000000000',\n",
       "       '2020-03-26T00:00:00.000000000', '2020-02-08T00:00:00.000000000',\n",
       "       '2020-03-22T00:00:00.000000000', '2020-02-03T00:00:00.000000000',\n",
       "       '2020-02-28T00:00:00.000000000', '2019-12-30T00:00:00.000000000',\n",
       "       '2019-12-31T00:00:00.000000000', '2020-01-24T00:00:00.000000000',\n",
       "       '2020-01-05T00:00:00.000000000', '2019-12-18T00:00:00.000000000',\n",
       "       '2019-12-25T00:00:00.000000000', '2020-01-01T00:00:00.000000000',\n",
       "       '2020-01-15T00:00:00.000000000', '2020-01-20T00:00:00.000000000',\n",
       "       '2020-01-03T00:00:00.000000000', '2020-01-07T00:00:00.000000000',\n",
       "       '2020-02-02T00:00:00.000000000', '2020-02-05T00:00:00.000000000',\n",
       "       '2020-02-06T00:00:00.000000000', '2020-02-10T00:00:00.000000000',\n",
       "       '2020-01-10T00:00:00.000000000', '2020-01-12T00:00:00.000000000',\n",
       "       '2020-01-16T00:00:00.000000000', '2020-02-11T00:00:00.000000000',\n",
       "       '2020-02-12T00:00:00.000000000', '2020-02-13T00:00:00.000000000',\n",
       "       '2020-02-14T00:00:00.000000000', '2020-02-15T00:00:00.000000000',\n",
       "       '2020-02-16T00:00:00.000000000', '2020-02-20T00:00:00.000000000',\n",
       "       '2020-01-22T00:00:00.000000000', '2020-02-09T00:00:00.000000000',\n",
       "       '2020-03-06T00:00:00.000000000', '2020-01-29T00:00:00.000000000',\n",
       "       '2020-03-03T00:00:00.000000000', '2020-01-27T00:00:00.000000000',\n",
       "       '2020-01-28T00:00:00.000000000', '2020-03-07T00:00:00.000000000',\n",
       "       '2020-01-25T00:00:00.000000000', '2020-01-26T00:00:00.000000000',\n",
       "       '2020-01-23T00:00:00.000000000', '2020-01-17T00:00:00.000000000',\n",
       "       '2020-01-02T00:00:00.000000000', '2020-03-31T00:00:00.000000000',\n",
       "       '2020-04-01T00:00:00.000000000', '2020-04-15T00:00:00.000000000',\n",
       "       '2020-04-05T00:00:00.000000000', '2020-04-04T00:00:00.000000000',\n",
       "       '2020-04-03T00:00:00.000000000', '2020-04-02T00:00:00.000000000',\n",
       "       '2020-04-29T00:00:00.000000000', '2020-04-07T00:00:00.000000000',\n",
       "       '2020-04-06T00:00:00.000000000', '2020-08-04T00:00:00.000000000',\n",
       "       '2020-04-16T00:00:00.000000000', '2020-12-03T00:00:00.000000000',\n",
       "       '2020-01-09T00:00:00.000000000', '2020-01-13T00:00:00.000000000',\n",
       "       '2020-04-28T00:00:00.000000000', '2020-12-02T00:00:00.000000000',\n",
       "       '2020-08-02T00:00:00.000000000', '2020-05-03T00:00:00.000000000',\n",
       "       '2020-11-03T00:00:00.000000000', '2020-10-03T00:00:00.000000000',\n",
       "       '2020-04-13T00:00:00.000000000', '2020-08-03T00:00:00.000000000',\n",
       "       '2020-01-04T00:00:00.000000000', '2020-05-04T00:00:00.000000000',\n",
       "       '2020-06-04T00:00:00.000000000', '2020-09-04T00:00:00.000000000',\n",
       "       '2020-10-04T00:00:00.000000000', '2020-12-04T00:00:00.000000000',\n",
       "       '2020-04-14T00:00:00.000000000', '2020-07-04T00:00:00.000000000',\n",
       "       '2020-04-30T00:00:00.000000000', '2020-04-27T00:00:00.000000000',\n",
       "       '2020-11-04T00:00:00.000000000', '2020-04-20T00:00:00.000000000',\n",
       "       '2020-09-03T00:00:00.000000000', '2020-07-03T00:00:00.000000000',\n",
       "       '2020-05-02T00:00:00.000000000', '2020-09-02T00:00:00.000000000',\n",
       "       '2020-10-02T00:00:00.000000000', '2020-06-03T00:00:00.000000000',\n",
       "       '2020-11-02T00:00:00.000000000', '2020-07-02T00:00:00.000000000',\n",
       "       '2020-06-02T00:00:00.000000000', '2020-04-21T00:00:00.000000000',\n",
       "       '2020-04-19T00:00:00.000000000', '2020-01-19T00:00:00.000000000',\n",
       "       '2020-01-18T00:00:00.000000000', '2020-01-21T00:00:00.000000000',\n",
       "       '2020-04-17T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want all acaps data\n",
    "\n",
    "cm = pd.concat([cm,ms,acaps])\n",
    "\n",
    "# Or just the mask data\n",
    "\n",
    "# cm = pd.concat([cm,ms,acaps_mask_data])\n",
    "cm = cm.dropna(subset=['Date Start'])\n",
    "cm['Date Start'] = pd.to_datetime(cm['Date Start'])\n",
    "cm['Date Start'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhcc = pd.read_csv('https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "jhd = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "JH2CM = {\n",
    "    'Korea, South':'South Korea',\n",
    "    'Taiwan*':'Taiwan',\n",
    "    ('China','Hong Kong'):'Hong Kong',\n",
    "    ('China','Macau'):'Macau',\n",
    "    ('Denmark','Faroe Islands'):'Faroe Islands',\n",
    "    'US':'United States',\n",
    "    'North Macedonia':'Macedonia'\n",
    "}\n",
    "\n",
    "\n",
    "def jh2cm(c,s):\n",
    "    if c in JH2CM:\n",
    "        return JH2CM[c]\n",
    "    elif (c,s) in JH2CM:\n",
    "        return JH2CM[(c,s)]\n",
    "    return c\n",
    "\n",
    "def pre_jh(jh,val=\"Confirmed Cases\"):\n",
    "    jh['Country/Region'] = [jh2cm(c,s) for c,s in jh[['Country/Region','Province/State']].values]\n",
    "    jh['Country/Region'] = [jh2cm(c,s) for c,s in jh[['Country/Region','Province/State']].values]\n",
    "\n",
    "    jh.drop(columns=['Lat','Long'],inplace=True)\n",
    "    jh = jh.groupby('Country/Region').sum().reset_index()\n",
    "    jh = pd.melt(jh,id_vars=['Country/Region'],value_vars=jh.columns[2:],value_name=val,var_name='Date')\n",
    "    jh['Date'] = pd.to_datetime(jh['Date'])\n",
    "    return jh\n",
    "\n",
    "jhcc, jhd = pre_jh(jhcc),pre_jh(jhd,val='Deaths')\n",
    "jhcc['Deaths'] = jhd['Deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COLS = {\n",
    "    'Symptomatic isolation - targeted':{'contact isolation - symptoms':1,\n",
    "                                        'cohort isolation - symptoms':1},\n",
    "    'Symptomatic isolation - blanket':{'cluster isolation - symptoms':1,\n",
    "                                       'blanket isolation - symptoms':2},\n",
    "    'Asymptomatic isolation - targeted':{'contact isolation - no symptoms':1,\n",
    "                                         'cohort isolation - no symptoms':2},\n",
    "    'Asymptomatic isolation - blanket':{'cluster isolation - no symptoms':1,\n",
    "                                        'blanket isolation - no symptoms':3,\n",
    "                                        'blanket curfew - no symptoms':2,\n",
    "                                        'natural village quarantine':3},\n",
    "    'Domestic travel restriction':{'domestic traveller quarantine':1,\n",
    "                                   'domestic travel ban':2,\n",
    "                                   'total vehicle ban':2},\n",
    "    'Nonessential business suspension':{'general nonessential business suspension':1,\n",
    "                                        'limited nonessential business suspension':0.5,\n",
    "                                   'remote work':0.5},\n",
    "    'International travel restriction':{'international traveller screening - risk countries':1,\n",
    "                                        'international traveller screening - all countries':2,\n",
    "                                        'international traveller quarantine - risk countries':3,\n",
    "                                        'international traveller quarantine - all countries':4,\n",
    "                                        'international travel ban - risk countries':5,\n",
    "                                        'international travel ban - all countries':6},\n",
    "    'Testing':{'testing numbers total':np.nan},\n",
    "    'Contact tracing':{'contacts traced total':np.nan},\n",
    "    'Mask wearing':{'public mask wearing data':np.nan},\n",
    "    'Hand washing':{'public handwashing data':np.nan}\n",
    "    \n",
    "}\n",
    "\n",
    "MIN_COLS = {\n",
    "    'Gatherings banned':['indoor gatherings banned',\n",
    "                        'outdoor gatherings banned']\n",
    "}\n",
    "\n",
    "CUMSUM_COLS = {\n",
    "    'Healthcare specialisation':['clinic specialisation',\n",
    "                                'case transport',\n",
    "                                'quarantine zone',\n",
    "                                'hospital specialisation',\n",
    "                                'healthcare entry screening',\n",
    "                                'remote medical treatment',\n",
    "                                'visiting in hospital banned'],\n",
    "    'Phone hotline':['phone line'],\n",
    "    'Assisting people to stay home':['unemployment benefits extension',\n",
    "                                    'eviction moratorium',\n",
    "                                    'isolation allowance',\n",
    "                                    'compulsory isolation'],\n",
    "    'Public cleaning':['public transport cleaning',\n",
    "                      'public facility cleaning'],\n",
    "    'Miscellaneous hygiene measures':['funeral hygiene',\n",
    "                                     'cash cleaning',\n",
    "                                     'cash banned'],\n",
    "    'Social distancing and hygiene advice':['risk communication',\n",
    "                                         'community engagement',\n",
    "                                         'coronavirus education activities',\n",
    "                                         'handshakes banned',\n",
    "                                         'social distancing advice',\n",
    "                                         'stay home advice',\n",
    "                                         'space minimum',\n",
    "                                         'outdoor person density',\n",
    "                                         'indoor person density',\n",
    "                                         'public venue screening',\n",
    "                                         'handwashing encouragement',\n",
    "                                         'public mask encouragement'],\n",
    "    'Hygiene supply':['public mask supply',\n",
    "                     'public mask and hygiene supply',\n",
    "                     'public hand sanitizer supply',\n",
    "                     'public venue screening'],\n",
    "    'School closure':['school closure',\n",
    "                     'university closure',\n",
    "                     'nursery school closure',\n",
    "                     'remote schooling',\n",
    "                     'public transport stopped'],\n",
    "    'Activity cancellation':['activity cancellation - other',\n",
    "                            'sports cancellation',\n",
    "                            'religious activity cancellation',\n",
    "                            'religious activity limitations',\n",
    "                            'weddings canceled',\n",
    "                            'very large event cancellation or postponement',\n",
    "                            'cultural activity limitation',\n",
    "                            'remote cultural content',\n",
    "                            'restaurant limitations',\n",
    "                            'closure of gathering places'],\n",
    "    'Resumption':['public transport resumed',\n",
    "                 'activity resumed',\n",
    "                 'business resumed'],\n",
    "    'Diagnostic criteria loosened':['diagnostic criteria loosened'],\n",
    "    'Diagnostic criteria tightened':['diagnostic criteria tightened']    \n",
    "}\n",
    "\n",
    "TEST_COLS = {    \n",
    "    'Testing criteria':{'test all':1,\n",
    "                       'test symptomatic':0.5,\n",
    "                       'cluster testing':0.3,\n",
    "                       'test contacts':0.1,\n",
    "                       'test cohorts':0.2,\n",
    "                       'test travellers':0.1,\n",
    "                       'test medical staff':0.1,\n",
    "                       'test vulnerable':0.1}\n",
    "}\n",
    "\n",
    "def default_values(kw):\n",
    "    for k, v in {**MAX_COLS,**TEST_COLS}.items():\n",
    "        if (kw in v) and (v[kw]!=np.nan):\n",
    "            return v[kw]\n",
    "    return np.nan\n",
    "\n",
    "def keywords(kws_quants):\n",
    "    res =  pd.DataFrame([(i,j[1]) \n",
    "                         for j in kws_quants.values \n",
    "                         for i in str(j[0]).split(', ')],\n",
    "                        columns=['Keywords','Quantity'])\n",
    "    res['Quantity'] = res['Keywords'].apply(default_values).fillna(res['Quantity'])\n",
    "    return res\n",
    "\n",
    "def sum_kws(kws_quants,tags):\n",
    "    return pd.Series(kws_quants['Keywords'].unique()).isin(tags).sum()\n",
    "\n",
    "def max_kws(kws_quants,tags):\n",
    "    return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].max()\n",
    "\n",
    "def min_kws(kws_quants,tags):\n",
    "    return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].min()\n",
    "\n",
    "def test_kws(kws_quants,tags):\n",
    "    if 'test all' in kws_quants['Keywords']:\n",
    "        return 1\n",
    "    elif 'test symptomatic' in kws_quants['Keywords']:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].sum()\n",
    "\n",
    "\n",
    "jdict = {**MAX_COLS,**MIN_COLS,**CUMSUM_COLS,**TEST_COLS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-18 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-19 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-20 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-21 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-22 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-23 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-24 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-25 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-26 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-27 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-28 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-29 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-30 00:00:00  of  2020-12-04 00:00:00\n",
      "2019-12-31 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-01 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-02 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-03 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-04 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-05 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-06 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-07 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-08 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-09 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-10 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-11 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-12 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-13 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-14 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-15 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-16 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-17 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-18 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-19 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-20 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-21 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-22 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-23 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-24 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-25 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-26 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-27 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-28 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-29 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-30 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-01-31 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-01 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-02 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-03 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-04 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-05 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-06 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-07 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-08 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-09 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-10 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-11 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-12 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-13 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-14 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-15 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-16 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-17 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-18 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-19 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-20 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-21 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-22 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-23 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-24 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-25 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-26 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-27 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-28 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-02-29 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-01 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-02 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-03 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-04 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-05 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-06 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-07 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-08 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-09 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-10 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-11 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-12 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-13 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-14 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-15 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-16 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-17 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-18 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-19 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-20 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-21 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-22 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-23 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-24 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-25 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-26 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-27 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-28 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-29 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-30 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-03-31 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-01 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-02 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-03 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-04 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-05 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-06 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-07 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-08 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-09 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-10 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-11 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-12 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-13 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-14 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-15 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-16 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-17 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-18 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-19 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-20 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-21 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-22 00:00:00  of  2020-12-04 00:00:00\n",
      "2020-04-23 00:00:00  of  2020-12-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "data_dict = {k:[] for k in jdict.keys()}\n",
    "data_dict['Date'] = []\n",
    "data_dict['Country'] = []\n",
    "\n",
    "for d in pd.date_range(cm['Date Start'].min(),pd.Timestamp('2020-04-23')):\n",
    "    print(d,' of ',cm['Date Start'].max())\n",
    "    for c in cm['Country'].unique():\n",
    "        data_dict['Country'].append(c)\n",
    "        data_dict['Date'].append(d)\n",
    "        if ((cm['Date Start']<=d)&(cm['Country']==c)).any():\n",
    "            kws_quants = keywords(cm[(cm['Date Start']<=d)&(cm['Country']==c)][['Keywords','Quantity']])\n",
    "        else:\n",
    "            kws_quants = pd.DataFrame({'Keywords':[],'Quantity':[]})\n",
    "        for col in MAX_COLS:\n",
    "            data_dict[col].append(max_kws(kws_quants,MAX_COLS[col].keys()))\n",
    "        for col in CUMSUM_COLS:\n",
    "            data_dict[col].append(sum_kws(kws_quants,CUMSUM_COLS[col]))\n",
    "        for col in TEST_COLS:\n",
    "            data_dict[col].append(test_kws(kws_quants,TEST_COLS[col].keys()))\n",
    "        for col in MIN_COLS:\n",
    "            data_dict[col].append(min_kws(kws_quants,MIN_COLS[col]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write 27 features data to file\n",
    "\n",
    "unmerged_data = pd.DataFrame(data_dict).dropna(subset=['Country'])\n",
    "\n",
    "djh = unmerged_data[unmerged_data['Country'].isin(jhcc['Country/Region'])]\n",
    "\n",
    "jhcc.rename(columns={'Country/Region':'Country'},inplace=True)\n",
    "jh_merged_data = djh.merge(jhcc,on=['Date','Country'])\n",
    "\n",
    "unmerged_data.to_csv(f'countermeasures_features_{DATE}-acaps.csv')\n",
    "jh_merged_data.to_csv(f'countermeasures_db_johnshopkins_{DATE}-acaps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modelling\n",
    "\n",
    "REPORTCOLS_BOOL = {'Gatherings limited to 10':('Gatherings banned',lambda x:(x<=10)&(x>0)),\n",
    "                   'Gatherings limited to 100':('Gatherings banned',lambda x:(x<=100)&(x>0)),\n",
    "                   'Gatherings limited to 1000':('Gatherings banned',lambda x: (x<=1000)&(x>0)),\n",
    "                  'Business suspended - some':('Nonessential business suspension',lambda x: x>=0.5),\n",
    "                  'Business suspended - many':('Nonessential business suspension',lambda x: x>=1),\n",
    "                  'Schools and universities closed':('School closure',lambda x: x>=1),\n",
    "                  'General curfew':('Asymptomatic isolation - blanket',lambda x: x>=2),\n",
    "                  'Healthcare specialisation':('Healthcare specialisation',lambda x: x>=2),\n",
    "                  'Mask wearing over 70%':('Mask wearing',lambda x: x>=70)}\n",
    "data0 = unmerged_data.copy()\n",
    "\n",
    "\n",
    "for rc, (vc, f) in REPORTCOLS_BOOL.items():\n",
    "    data0[rc] = data0[vc].apply(f).astype(float)\n",
    "\n",
    "model_data = data0[list(REPORTCOLS_BOOL.keys())+['Country','Date']]\n",
    "model_data = model_data[pd.to_datetime(model_data['Date'])<=pd.Timestamp(date.today())]\n",
    "\n",
    "regions = pd.read_csv(f'{DATA_DIR}/regions.csv')\n",
    "\n",
    "model_data = model_data[model_data['Country'].isin(regions['Name'])]\n",
    "model_data.loc[:,'Country'] = model_data['Country'].apply(lambda x: regions[regions['Name']==x]['Code'].iloc[0])\n",
    "\n",
    "# For some reason Namibia gets NaN as a code\n",
    "\n",
    "model_data['Country'] = model_data['Country'].replace(np.nan,'NA')\n",
    "model_data = model_data.rename(columns={'Country':'Code'})\n",
    "model_data[~model_data['Country'].str.startswith('United States')].to_csv(f'countermeasures-model-boolean-{DATE}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
